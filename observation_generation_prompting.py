import json
import re
from search import OBSERVATION_GEN_TEMP
from pprint import pprint
from dotenv import load_dotenv
load_dotenv() 
from openai import OpenAI

from prompting_utils import grid_to_python_literal
from task import Task, TaskDataset, get_task



def generate_observation_prompt(
        num_observations: int,
        task: Task,
        additional_context: str = ""
) -> list[dict]:
    """
    Generate a prompt for generating observations about a task.

    Parameters:
    ----------
    num_observations: int
        The number of observations to generate.
    task: Task
        The task to generate observations about.
    additional_context: str, optional
        Additional context or instructions to guide the observation generation. Used to refine existing observations.

    Returns:
    -------
        An OpenAI message history.
    """
    base_prompt = (
        f"Please provide {num_observations} observations about "
        f"the nature of the transformations, the input grids, or "
        f"the output grids. Output your observations as a numbered "
        f"list."
    )
    
    # Combine base prompt with additional context if provided
    full_prompt = base_prompt + additional_context

    content = [
        {
            "type": "text",
            "text": full_prompt
        }
    ]
    for example in task.examples_with_images:
        base64_image = example['base64_image']
        input_literal = grid_to_python_literal(example['input'])
        output_literal = grid_to_python_literal(example['output'])

        content.append(
            {
                "type": "image_url",
                "image_url": {
                    "url": f"data:image/png;base64,{base64_image}"
                }
            }
        )
        content.append(
            {
                "type": "text",
                "text": (
                    f"Python Representation:\n"
                    f"Input Grid:\n{input_literal}\n"
                    f"Output Grid:\n{output_literal}"
                )
            }
        )
    return [
        {
            "role": "user",
            "content": content
        }
    ]


# Example: Autogenerated observation.
# This is *data*; it can be put in a file later.
FSP_RAW = [
    {
        "file_path": "arc-agi_training_challenges.json",
        "task_id": "007bbfb7",
        "observations_to_generate": 10,
        "observation": (
            "Here are 10 observations based on the provided transformations between "
            "the input grids and the output grids:\n\n"
            "1. **Expansion of Dimensions**: Each transformation results in an output "
            "grid with larger dimensions (typically 3 times wider and taller in the "
            "examples shown), indicating spatial expansion.\n\n"
            "2. **Color Retention**: The colors present in the input grids are "
            "maintained in the output grids; no new colors are introduced and each "
            "specific number corresponds to a predefined color.\n\n"
            "3. **Positional Changes**: The arrangement of colored squares often shifts "
            "dramatically; for instance, groups of colors in the input grid can "
            "appear segmented and rearranged in the output grid.\n\n"
            "4. **Zero Dominance**: The black color (represented by 0) occupies a "
            "significant portion of the output grids, serving as a background while "
            "colored elements are embedded within it to create patterns.\n\n"
            "5. **Regular Patterns**: Many output grids exhibit repetitive patterns "
            "or symmetrical placements of colors throughout the grid, suggesting a "
            "systematic transformation from the input structure.\n\n"
            "6. **Non-linear Distribution**: Transition from the input grids to output "
            "grids does not maintain linear uniformity; rather, colors can cluster "
            "together or create isolated patches that do not follow a straightforward "
            "distribution.\n\n"
            "7. **Selective Surety**: Some colored areas in the input grids are entirely "
            "omitted in the output grids, indicating a selective transformation where "
            "certain colors or positional instances are favored over others.\n\n"
            "8. **Frequency of Color**: In multiple transformations, certain colors "
            "appear more frequently in their respective output grids compared to "
            "others. This may suggest a prominence or emphasis on specific hues in "
            "the transformed designs.\n\n"
            "9. **Spatial Connectivity**: Some colored regions maintain relative "
            "proximity to their positions in the input grids, forming linked patterns "
            "like cross shapes or vertical columns in the output grids.\n\n"
            "10. **Transformation Complexity**: The transformations often exhibit "
            "complexity in shape; for example, the distinct color patterns within the "
            "output grid generate a visual discontinuity relative to the relatively "
            "simple input shapes, indicating more intricate design transformations."
        )
    }
]


def generate_fsp_context(
    fsp_data: list[dict]
) -> list[dict]:
    system_prompt = (
        "You are an expert at analyzing transformations between grids. "
        "Your task is to analyze the transformations shown in the following "
        "examples and provide a list of observations about the nature of the "
        "transformations, the input grids, or the output grids. "
        "Your goal is to be very, very, very, very, very insightful! "
        "Here's what color each number corresponds to. "
        "0: Black, 1: Blue, 2: Red, 3: Green, 4: Yellow, 5: Gray, "
        "6: Magenta, 7: Orange, 8: Cyan, 9: Brown."
    )
    messages = [
        {
            "role": "system",
            "content": system_prompt
        }
    ]

    # Add examples
    for example in fsp_data:
        messages.extend(
            generate_observation_prompt(
                num_observations=example['observations_to_generate'],
                task=get_task(example['file_path'],
                              example['task_id'])
            )
        )
        messages.append(
            {
                "role": "assistant",
                "content": example['observation']
            }
        )

    return messages


FSP_CONTEXT = generate_fsp_context(FSP_RAW)


def generate_observations(
        client: OpenAI,
        num_observations: int,
        task: Task,
        verbose: bool = False,
        max_observations_per_call: int = 10,
        additional_context: str = ""
) -> list[str]:
    """
    Generate observations about a task.

    Implementation note:
     - First off, OpenAI should do prefix caching for the massive FSP context.
     - Second, we only make one call to GPT-4o-mini, and let it generate
       as many observations as it can given the token limit. We set a high
       n so that the prefix is used in all n rollouts.
     - Adjust num_observations to stay within token limits.
     - Decrease max_observations_per_call so the model doesn't behave badly.

    Future idea: include things that we are "currently interested in"
    to guide the generation of observations. The current generation method
    probably yields many overlapping observations between rollouts.

    Parameters:
    ----------
    client: OpenAI
        The OpenAI client to use to generate observations.
    num_observations: int
        The number of observations to generate.
    task: Task
        The task to generate observations about.
    additional_context: str, optional
        Additional context or instructions to guide the observation generation; used when refining observations.
    """

    # Construct the prompt
    messages = []

    messages.extend(FSP_CONTEXT)

    messages.extend(
        generate_observation_prompt(
            num_observations=max_observations_per_call,
            task=task,
            additional_context=additional_context  # Pass the additional context
        )
    )

    if verbose:
        print("Messages:")
        pprint(messages)

    # Make the API call using the OpenAI client
    completion = client.chat.completions.create(
        model="gpt-4o-mini",
        messages=messages,
        max_tokens=2048,
        n=num_observations // max_observations_per_call,
        temperature=OBSERVATION_GEN_TEMP
    )

    observations = []
    if verbose:
        print("Responses:")
    for response in completion.choices:
        response_content = response.message.content
        if verbose:
            print(response_content)
        for observation in response_content.split('\n'):
            match = re.match(r'^\s*(\d+)\.\s*(.*)$', observation)
            if match:
                observations.append(match.group(2))

    if verbose:
        print("Observations:")
        pprint(observations)
    return observations


def main():
    """
    Test the functions.
    """

    task = get_task('arc-agi_training_challenges.json', '00d62c1b')

    client = OpenAI()
    generate_observations(
        client=client,
        num_observations=10,
        task=task,
        verbose=True
    )


if __name__ == "__main__":
    main()
