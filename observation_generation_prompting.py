import json
import re
from pprint import pprint
from typing import Optional

from openai import OpenAI

from prompting_utils import grid_to_python_literal
from task import Task, TaskDataset

observation_gen_temp = 1.1


def generate_observation_prompt(
        num_observations: int,
        task: list[dict]
) -> list[dict]:
    """
    Generate a prompt for generating observations about a task.

    Parameters:
    ----------
    num_observations: int
        The number of observations to generate.
    task: list[dict]
        A single task consists of many examples.
        Each example is a dictionary with the following keys:
        - base64_image: str
            The base64 encoded image of the task.
        - input: list[list[int]]
            The input grid of the task.
        - output: list[list[int]]
            The output grid of the task.

    Returns:
    -------
    list[dict]
        An OpenAI message history. The current implementation only uses one message,
        but for future-proofing, we return a list of messages.
    """
    content = [
        {
            "type": "text",
            "text": (
                f"Please provide {num_observations} observations about "
                f"the nature of the transformations, the input grids, or "
                f"the output grids. Output your observations as a numbered "
                f"list."
            )
        }
    ]
    for example in task:
        base64_image = example['base64_image']
        input_literal = grid_to_python_literal(example['input'])
        output_literal = grid_to_python_literal(example['output'])

        content.append(
            {
                "type": "image_url",
                "image_url": {
                    "url": f"data:image/png;base64,{base64_image}"
                }
            }
        )
        content.append(
            {
                "type": "text",
                "text": (
                    f"Python Representation:\n"
                    f"Input Grid:\n{input_literal}\n"
                    f"Output Grid:\n{output_literal}"
                )
            }
        )
    return [
        {
            "role": "user",
            "content": content
        }
    ]


# Example: Autogenerated observation.
# This is *data*; it can be put in a file later.
FSP_OBSERVATIONS = {
    {
        "file_path": "arc-agi_training_challenges.json",
        "task_id": "007bbfb7",
        "observations_to"
        "observation": (
            "Here are 10 observations based on the provided transformations between "
            "the input grids and the output grids:\n\n"
            "1. **Expansion of Dimensions**: Each transformation results in an output "
            "grid with larger dimensions (typically 3 times wider and taller in the "
            "examples shown), indicating spatial expansion.\n\n"
            "2. **Color Retention**: The colors present in the input grids are "
            "maintained in the output grids; no new colors are introduced and each "
            "specific number corresponds to a predefined color.\n\n"
            "3. **Positional Changes**: The arrangement of colored squares often shifts "
            "dramatically; for instance, groups of colors in the input grid can "
            "appear segmented and rearranged in the output grid.\n\n"
            "4. **Zero Dominance**: The black color (represented by 0) occupies a "
            "significant portion of the output grids, serving as a background while "
            "colored elements are embedded within it to create patterns.\n\n"
            "5. **Regular Patterns**: Many output grids exhibit repetitive patterns "
            "or symmetrical placements of colors throughout the grid, suggesting a "
            "systematic transformation from the input structure.\n\n"
            "6. **Non-linear Distribution**: Transition from the input grids to output "
            "grids does not maintain linear uniformity; rather, colors can cluster "
            "together or create isolated patches that do not follow a straightforward "
            "distribution.\n\n"
            "7. **Selective Surety**: Some colored areas in the input grids are entirely "
            "omitted in the output grids, indicating a selective transformation where "
            "certain colors or positional instances are favored over others.\n\n"
            "8. **Frequency of Color**: In multiple transformations, certain colors "
            "appear more frequently in their respective output grids compared to "
            "others. This may suggest a prominence or emphasis on specific hues in "
            "the transformed designs.\n\n"
            "9. **Spatial Connectivity**: Some colored regions maintain relative "
            "proximity to their positions in the input grids, forming linked patterns "
            "like cross shapes or vertical columns in the output grids.\n\n"
            "10. **Transformation Complexity**: The transformations often exhibit "
            "complexity in shape; for example, the distinct color patterns within the "
            "output grid generate a visual discontinuity relative to the relatively "
            "simple input shapes, indicating more intricate design transformations."
        )
    }
}


def generate_fsp_context(
    fsp_dataset: TaskDataset,
    fsp_data: dict
) -> list[dict]:
    system_prompt = (
        "You are an expert at analyzing transformations between grids. "
        "Your task is to analyze the transformations shown in the following examples and provide a list of observations about the nature of the transformations, the input grids, or the output grids. "
        "Your goal is to be very, very, very, very, very insightful! "
        "Here's what color each number corresponds to. 0: Black, 1: Blue, 2: Red, 3: Green, 4: Yellow, 5: Gray, 6: Magenta, 7: Orange, 8: Cyan, 9: Brown."
    )
    messages = [
        {
            "role": "system",
            "content": system_prompt
        }
    ]

    # Add examples
    for idx, example in enumerate(fsp_data['train']):
        solution = example['solution']
        messages.extend(
            generate_observation_prompt(
                num_observations=fsp_data['observations_to_generate'],
                task=example
            )
        )
        messages.append(
            {
                "role": "assistant",
                "content": solution
            }
        )

    return messages


def generate_observations(
        client: OpenAI,
        num_observations: int,
        task: Task,
        verbose: bool = False
) -> list[str]:
    """
    Generate observations about a task.

    Future idea: include things that we are "currently interested in"
    to guide the generation of observations.

    Parameters:
    ----------
    client: OpenAI
        The OpenAI client to use to generate observations.
    num_observations: int
        The number of observations to generate.
    task: Task
        The task to generate observations about.
    """

    # Hard limit: adjust the number of observations per call to stay within token limits
    # Soft limit: if this is too high, the model will probably behave badly.
    max_observations_per_call = 10
    total_observations = []
    observations_remaining = num_observations

    while observations_remaining > 0:
        observations_to_request = min(
            observations_remaining, max_observations_per_call)
        # Construct the prompt
        messages = []

        messages.extend(
            generate_fsp_context(
                FSP_OBSERVATIONS,
            )
        )

        messages.extend(
            generate_observation_prompt(
                num_observations=observations_to_request,
                task=examples
            )
        )

        if verbose:
            print("Messages:")
            pprint(messages)

        # Make the API call using the OpenAI client
        completion = client.chat.completions.create(
            model="gpt-4o-mini",
            messages=messages,
            max_tokens=2048,
            n=1,
            temperature=observation_gen_temp
        )
        response_content = completion.choices[0].message.content

        if verbose:
            print("Response:")
            print(response_content)

        observations = []
        for observation in response_content.split('\n'):
            match = re.match(r'^\s*(\d+)\.\s*(.*)$', observation)
            if match:
                observations.append(match.group(2))

        total_observations.extend(observations)
        observations_remaining -= observations_to_request

    return total_observations


def main():
    """
    Test the functions.
    """

    arc_tasks = TaskDataset('arc-agi_training_challenges.json')
    task = arc_tasks['007bbfb7']['train'][0]

    client = OpenAI()
    observations = generate_observations(
        client=client,
        num_observations=10,
        task=task,
        verbose=True
    )
    print(observations)


if __name__ == "__main__":
    main()
